{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('../ops_modules')\n",
    "from parse_email import ParseMailData\n",
    "from content_scanner import Scanner "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e107109/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.22.1 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Knn\n",
    "with open('../ML_algorithms/Models/best_knn.pickle', 'rb') as data:\n",
    "    knn = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_test\n",
    "with open('../Pickles/features_test.pickle', 'rb') as data:\n",
    "    features_test = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e107109/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.22.1 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/e107109/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22.1 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('../Pickles/tfidf.pickle', 'rb') as data:\n",
    "    tfidf = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Predictions/test_data/ML_data.pickle',  'rb') as data:\n",
    "    ML_test_data = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Test Data](#test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>parsed_lemmatized_text</th>\n",
       "      <th>stop_words_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sa direct enrolled ||stage||health service con...</td>\n",
       "      <td>Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...</td>\n",
       "      <td>14</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>hi team    could you please make the health co...</td>\n",
       "      <td>hi team    could you please make the health co...</td>\n",
       "      <td>hi team    could  please make  health configur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  sa direct enrolled ||stage||health service con...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...   14   Aug  2020   \n",
       "\n",
       "        Date                                   Content_Parsed_1  \\\n",
       "0 2020-08-14  hi team    could you please make the health co...   \n",
       "\n",
       "                              parsed_lemmatized_text  \\\n",
       "0  hi team    could you please make the health co...   \n",
       "\n",
       "                                   stop_words_parsed  \n",
       "0  hi team    could  please make  health configur...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_test_data.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_data/test_data.CSV', encoding=\"ISO-8859-1\")\n",
    "df = df.fillna('dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test\"></a>\n",
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e107109/email-classifer-demo/ML_testData/../ops_modules/content_scanner.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Subject'][index] = subject + \" \" + str(random())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re: question about api standards</td>\n",
       "      <td>Thanks John.\\r\\n\\r\\n \\r\\n\\r\\nWe will review th...</td>\n",
       "      <td>14</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-09-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Subject  \\\n",
       "0  re: question about api standards   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Thanks John.\\r\\n\\r\\n \\r\\n\\r\\nWe will review th...   14   Sep  2021   \n",
       "\n",
       "        Date  \n",
       "0 2021-09-14  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_obj = ParseMailData('test_data/test_data.CSV')\n",
    "parse_df = parse_obj.parse()\n",
    "current_year = datetime.now().year\n",
    "current_month = datetime.now().strftime('%h')\n",
    "parse_df.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re: supported cards vs supported payments</td>\n",
       "      <td>Yes Thatâs correct Charlie, he wants to chan...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creditor management, creditor retrieval - refe...</td>\n",
       "      <td>Hi, \\r\\n\\r\\n \\r\\n\\r\\nOn the FAQs of the Self-A...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0          re: supported cards vs supported payments   \n",
       "1  creditor management, creditor retrieval - refe...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Yes Thatâs correct Charlie, he wants to chan...    1   Sep  2022   \n",
       "1  Hi, \\r\\n\\r\\n \\r\\n\\r\\nOn the FAQs of the Self-A...    1   Sep  2022   \n",
       "\n",
       "        Date  \n",
       "0 2022-09-01  \n",
       "1 2022-09-01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_df_current = parse_df.loc[(parse_df['Month'] == (pd.Period(datetime.now(), 'M') - 1).strftime('%b')) & (parse_df['Year'] == current_year)]\n",
    "parse_df_current = parse_df_current.reset_index(drop=True)\n",
    "parse_df_current.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Predictions](#predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_creation(content_parsed):\n",
    "    # Removing \\r \\n and extra spaces\n",
    "    content_parsed['Content_Parsed_1'] = content_parsed['Body'].str.replace(\"\\r\", \" \")\n",
    "    content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "    content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
    "    # content_parsed['Category'] = category_subject_df['Category']\n",
    "\n",
    "    # Removing \" when quoting text\n",
    "    content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace('\"', '')\n",
    "\n",
    "    # Lowercasing the text\n",
    "    content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.lower()\n",
    "\n",
    "    # Removing common non-relevant occuring words\n",
    "    ignore_words = ['mastercard', 'com', 'senior', 'software', 'engineer', 'mountainview', 'central', 'park', 'leopardstown',\n",
    "                    'dublin', '18', 'ireland', 'cc', 'subject', 'mailto', 'api_consultancy_and_standards', 'api_onboarding']\n",
    "    for ig_word in ignore_words:\n",
    "        content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace(ig_word, ' ')\n",
    "\n",
    "    # Removing punctuation signs and other unwanted symbols\n",
    "    punctuation_signs = list(\"?:!.,;<>|@\")\n",
    "\n",
    "    for punct_sign in punctuation_signs:\n",
    "        content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace(punct_sign, ' ')\n",
    "\n",
    "    # Removing possessive nouns\n",
    "    content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace(\"'s\", \" \")\n",
    "    \n",
    "    ##### Lemmatization #####\n",
    "    # Saving the lemmatizer into an object\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_text_list = []\n",
    "\n",
    "    for row in range(0, len(content_parsed)):\n",
    "\n",
    "        # Create an empty list containing lemmatized words\n",
    "        lemma_list = []\n",
    "\n",
    "        # Save the text and its words into an object\n",
    "        text = content_parsed.loc[row]['Content_Parsed_1']\n",
    "        text_words = text.split(\" \")\n",
    "\n",
    "        # Iterate through every word to lemmatize\n",
    "        for word in text_words:\n",
    "            lemma_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "\n",
    "        # Join the list\n",
    "        lemma_text = \" \".join(lemma_list)\n",
    "\n",
    "        # Append to the list containing the texts\n",
    "        lemma_text_list.append(lemma_text)\n",
    "\n",
    "    content_parsed['parsed_lemmatized_text'] = lemma_text_list\n",
    "    \n",
    "    ##### Stop words removal #####\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    # Adding the stopwords from the TO: From: CC: column\n",
    "    # which is all the names\n",
    "\n",
    "    stop_words_df = pd.DataFrame({})\n",
    "    stop_words_df['From: (Name)'] = df['From: (Name)']\n",
    "    stop_words_df['To: (Name)'] = df['To: (Name)']\n",
    "    stop_words_df['CC: (Name)'] = df['CC: (Name)']\n",
    "    #stop_words_df = df_distinct.iloc[:, :2]\n",
    "\n",
    "    for column in stop_words_df:\n",
    "        # Lowercasing the text\n",
    "        stop_words_df[column] = stop_words_df[column].str.lower()\n",
    "\n",
    "        # Removing punctuation signs and other unwanted symbols\n",
    "        stop_words_df[column] = stop_words_df[column].str.replace('dummy', '')\n",
    "\n",
    "        # Removing punctuation signs and other unwanted symbols\n",
    "        stop_words_punctuation_signs = list(\",;)(\")\n",
    "\n",
    "        for stop_words_punct_sign in stop_words_punctuation_signs:\n",
    "            stop_words_df[column] = stop_words_df[column].str.replace(stop_words_punct_sign, ' ')\n",
    "            \n",
    "    word = list()\n",
    "    for i in range(0, len(stop_words_df)):\n",
    "        for j in stop_words_df.loc[i].values:\n",
    "            word.append(j.split())\n",
    "    new_stop_words = [item for sublist in word for item in sublist]\n",
    "\n",
    "\n",
    "    stop_words_unique = set(new_stop_words) # To get unique values\n",
    "    \n",
    "    stop_words.extend(stop_words_unique)\n",
    "    remove_words = ['jamstack', 'onboarding', 'support', 'product', 'operations', 'api', 'apis', 'project', \n",
    "                    'architecture', 'security', 'development', 'key', 'jenkins', 'dev', 'external', 'team', 'digital',\n",
    "                    'helpdesk', 'axon', 'gateway', 'xmlgw', 'access', 'ping', 'strategic', 'developers', 'postgres',\n",
    "                    'management', 'xml', 'gw', 'service', 'dba', 'standards']\n",
    "\n",
    "    for w in remove_words:\n",
    "        if w in stop_words:\n",
    "            stop_words.remove(w)\n",
    "        \n",
    "    # Takes time to process 5-6 mins.\n",
    "    # This is to remove all the stopwords from the Body.\n",
    "    content_parsed['stop_words_parsed'] = content_parsed['parsed_lemmatized_text']\n",
    "    for stop_word in stop_words:\n",
    "        if (stop_word == '?ukasz'):\n",
    "            stop_word = '\\?ukasz'\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        content_parsed['stop_words_parsed'] = content_parsed['stop_words_parsed'].str.replace(regex_stopword, '')\n",
    "\n",
    "    # Removing the unwanted columns\n",
    "    content_parsed = content_parsed.drop(['Content_Parsed_1', 'parsed_lemmatized_text'], axis=1)\n",
    "    \n",
    "    # Renaming the parsed column\n",
    "    content_parsed = content_parsed.rename(columns={'stop_words_parsed': 'Content_Parsed'})\n",
    "    \n",
    "    # TF-IDF\n",
    "    features = tfidf.transform(content_parsed['Content_Parsed']).toarray()\n",
    "    \n",
    "    return features, content_parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_name(category_id):\n",
    "    category_codes = {'1' : 'Service Proxy troubleshooting / APIGW', \n",
    "                      '2' : 'Onboarding generic queries',\n",
    "                      '3' : 'Assessment/rescore queries/early spec/exception requests',\n",
    "                      '4' : 'Access to Tool queries', \n",
    "                      '5' : 'API Standards queries',\n",
    "                      '6' : 'zally',\n",
    "                      '7' : 'Client libs', \n",
    "                      '8' : 'Jamstack content reviewer',\n",
    "                      '9' : 'Axon Queries',\n",
    "                      '10': 'Mastercard Developers Notification'\n",
    "                     }\n",
    "    for cid, cname  in category_codes.items():    \n",
    "        if cid == category_id:\n",
    "            return cname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_features(features):\n",
    "        \n",
    "    # Obtain the highest probability of the predictions for each mail\n",
    "    predictions_proba = knn.predict_proba(features).max(axis=1)    \n",
    "    \n",
    "    # Predict using the input model\n",
    "    predictions_pre = knn.predict(features)\n",
    "\n",
    "    # Replace prediction with 6 if associated cond. probability less than threshold\n",
    "    predictions = []\n",
    "\n",
    "    for prob, cat in zip(predictions_proba, predictions_pre):\n",
    "        if prob > .65:\n",
    "            predictions.append(cat)\n",
    "        else:\n",
    "            predictions.append(5)\n",
    "\n",
    "    # Return result\n",
    "    categories = [get_category_name(x) for x in predictions]\n",
    "    \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_df(df, categories):\n",
    "    df['Prediction'] = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yz/nmc9qxpd275fmy5s0tx2wxqxvypjj6/T/ipykernel_90845/819961952.py:24: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  content_parsed['Content_Parsed_1'] = content_parsed['Content_Parsed_1'].str.replace(punct_sign, ' ')\n",
      "/var/folders/yz/nmc9qxpd275fmy5s0tx2wxqxvypjj6/T/ipykernel_90845/819961952.py:77: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  stop_words_df[column] = stop_words_df[column].str.replace(stop_words_punct_sign, ' ')\n",
      "/var/folders/yz/nmc9qxpd275fmy5s0tx2wxqxvypjj6/T/ipykernel_90845/819961952.py:105: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  content_parsed['stop_words_parsed'] = content_parsed['stop_words_parsed'].str.replace(regex_stopword, '')\n"
     ]
    }
   ],
   "source": [
    "# Features creation\n",
    "features, df_show_info = feature_creation(parse_df_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re: supported cards vs supported payments</td>\n",
       "      <td>Yes Thatâs correct Charlie, he wants to chan...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>yes thatâ correct    want  change  header  s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creditor management, creditor retrieval - refe...</td>\n",
       "      <td>Hi, \\r\\n\\r\\n \\r\\n\\r\\nOn the FAQs of the Self-A...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>hi       faqs   selfassessment tutorial  confl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0          re: supported cards vs supported payments   \n",
       "1  creditor management, creditor retrieval - refe...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Yes Thatâs correct Charlie, he wants to chan...    1   Sep  2022   \n",
       "1  Hi, \\r\\n\\r\\n \\r\\n\\r\\nOn the FAQs of the Self-A...    1   Sep  2022   \n",
       "\n",
       "        Date                                     Content_Parsed  \n",
       "0 2022-09-01  yes thatâ correct    want  change  header  s...  \n",
       "1 2022-09-01  hi       faqs   selfassessment tutorial  confl...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_show_info.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>parsed_lemmatized_text</th>\n",
       "      <th>stop_words_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sa direct enrolled ||stage||health service con...</td>\n",
       "      <td>Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...</td>\n",
       "      <td>14</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>hi team    could you please make the health co...</td>\n",
       "      <td>hi team    could you please make the health co...</td>\n",
       "      <td>hi team    could  please make  health configur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>re: track bps : axon topic creation request fo...</td>\n",
       "      <td>[Attaching Splunk output]\\r\\n\\r\\n \\r\\n\\r\\nRoss...</td>\n",
       "      <td>17</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>[attaching splunk output]   ross phelan       ...</td>\n",
       "      <td>[attaching splunk output]   ross phelan       ...</td>\n",
       "      <td>[attaching splunk output]               api pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  sa direct enrolled ||stage||health service con...   \n",
       "1  re: track bps : axon topic creation request fo...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...   14   Aug  2020   \n",
       "1  [Attaching Splunk output]\\r\\n\\r\\n \\r\\n\\r\\nRoss...   17   Aug  2020   \n",
       "\n",
       "        Date                                   Content_Parsed_1  \\\n",
       "0 2020-08-14  hi team    could you please make the health co...   \n",
       "1 2020-08-17  [attaching splunk output]   ross phelan       ...   \n",
       "\n",
       "                              parsed_lemmatized_text  \\\n",
       "0  hi team    could you please make the health co...   \n",
       "1  [attaching splunk output]   ross phelan       ...   \n",
       "\n",
       "                                   stop_words_parsed  \n",
       "0  hi team    could  please make  health configur...  \n",
       "1  [attaching splunk output]               api pl...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_test_data = pd.concat([ML_test_data, parse_df_current], ignore_index=True)\n",
    "ML_test_data = ML_test_data.drop_duplicates(subset=['Subject']).reset_index(drop=True)\n",
    "ML_test_data.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predictions\"></a>\n",
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = predict_from_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API Standards queries',\n",
       " 'API Standards queries',\n",
       " 'API Standards queries',\n",
       " 'Assessment/rescore queries/early spec/exception requests',\n",
       " 'API Standards queries']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re: supported cards vs supported payments</td>\n",
       "      <td>Yes Thatâs correct Charlie, he wants to chan...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>yes thatâ correct    want  change  header  s...</td>\n",
       "      <td>API Standards queries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creditor management, creditor retrieval - refe...</td>\n",
       "      <td>Hi, \\r\\n\\r\\n \\r\\n\\r\\nOn the FAQs of the Self-A...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>hi       faqs   selfassessment tutorial  confl...</td>\n",
       "      <td>API Standards queries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0          re: supported cards vs supported payments   \n",
       "1  creditor management, creditor retrieval - refe...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Yes Thatâs correct Charlie, he wants to chan...    1   Sep  2022   \n",
       "1  Hi, \\r\\n\\r\\n \\r\\n\\r\\nOn the FAQs of the Self-A...    1   Sep  2022   \n",
       "\n",
       "        Date                                     Content_Parsed  \\\n",
       "0 2022-09-01  yes thatâ correct    want  change  header  s...   \n",
       "1 2022-09-01  hi       faqs   selfassessment tutorial  confl...   \n",
       "\n",
       "              Prediction  \n",
       "0  API Standards queries  \n",
       "1  API Standards queries  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put into dataset\n",
    "df_predictions_current = complete_df(df_show_info, predictions)\n",
    "df_predictions_current.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the current predictions with the previous data\n",
    "with open('Predictions/test_data/knn_test.pickle', 'rb') as data:\n",
    "    previous_data = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sa direct enrolled ||stage||health service con...</td>\n",
       "      <td>Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...</td>\n",
       "      <td>14</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>hi team    could  please make  health configur...</td>\n",
       "      <td>API Standards queries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>re: track bps : axon topic creation request fo...</td>\n",
       "      <td>[Attaching Splunk output]\\r\\n\\r\\n \\r\\n\\r\\nRoss...</td>\n",
       "      <td>17</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>[attaching splunk output]               api pl...</td>\n",
       "      <td>Onboarding generic queries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  sa direct enrolled ||stage||health service con...   \n",
       "1  re: track bps : axon topic creation request fo...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...   14   Aug  2020   \n",
       "1  [Attaching Splunk output]\\r\\n\\r\\n \\r\\n\\r\\nRoss...   17   Aug  2020   \n",
       "\n",
       "        Date                                     Content_Parsed  \\\n",
       "0 2020-08-14  hi team    could  please make  health configur...   \n",
       "1 2020-08-17  [attaching splunk output]               api pl...   \n",
       "\n",
       "                   Prediction  \n",
       "0       API Standards queries  \n",
       "1  Onboarding generic queries  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_data.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sa direct enrolled ||stage||health service con...</td>\n",
       "      <td>Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...</td>\n",
       "      <td>14</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>hi team    could  please make  health configur...</td>\n",
       "      <td>API Standards queries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>re: track bps : axon topic creation request fo...</td>\n",
       "      <td>[Attaching Splunk output]\\r\\n\\r\\n \\r\\n\\r\\nRoss...</td>\n",
       "      <td>17</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>[attaching splunk output]               api pl...</td>\n",
       "      <td>Onboarding generic queries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  sa direct enrolled ||stage||health service con...   \n",
       "1  re: track bps : axon topic creation request fo...   \n",
       "\n",
       "                                                Body  Day Month  Year  \\\n",
       "0  Hi Team,\\r\\n\\r\\n \\r\\n\\r\\nCould you please make...   14   Aug  2020   \n",
       "1  [Attaching Splunk output]\\r\\n\\r\\n \\r\\n\\r\\nRoss...   17   Aug  2020   \n",
       "\n",
       "        Date                                     Content_Parsed  \\\n",
       "0 2020-08-14  hi team    could  please make  health configur...   \n",
       "1 2020-08-17  [attaching splunk output]               api pl...   \n",
       "\n",
       "                   Prediction  \n",
       "0       API Standards queries  \n",
       "1  Onboarding generic queries  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending the current predictions with the previous data\n",
    "total_data = pd.concat([previous_data, df_predictions_current], ignore_index=True)\n",
    "total_data = total_data.drop_duplicates(subset=['Subject'])\n",
    "total_data = total_data.reset_index(drop=True)\n",
    "total_data.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving ML_test_data with updated values in df pickle file\n",
    "with open('Predictions/test_data/ML_data.pickle', 'wb') as output:\n",
    "    pickle.dump(ML_test_data, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predicted values in df pickle file    \n",
    "with open('Predictions/test_data/knn_test.pickle', 'wb') as output:\n",
    "    pickle.dump(total_data, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
